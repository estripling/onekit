{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pythonkit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import functools\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import time_machine\n",
    "from toolz import curried\n",
    "\n",
    "from onekit import pythonkit as pk\n",
    "from onekit import timekit as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `flatten`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 2, 3, 4, 'five', 'six', 'seven', 8, 9, 'ten']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irregular_list = [\n",
    "    [\"one\", 2],\n",
    "    3,\n",
    "    [(4, \"five\")],\n",
    "    [[[\"six\"]]],\n",
    "    \"seven\",\n",
    "    [],\n",
    "]\n",
    "\n",
    "list(pk.flatten(irregular_list, 8, [9, (\"ten\",)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `highlight_string_differences`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use in an `assert` statement to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lft_str = \"hello\"\n",
    "rgt_str = \"hallo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common approach to print values might not be informative enough for subtle differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/zd/ffdggf1d63v1hgsm0s2ddt480000gn/T/ipykernel_14667/54865336.py\", line 2, in <module>\n",
      "    assert lft_str == rgt_str, f\"{lft_str} != {rgt_str}\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: hello != hallo\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert lft_str == rgt_str, f\"{lft_str} != {rgt_str}\"\n",
    "except AssertionError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `highlight_string_differences`, it is easier to spot subtle differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/zd/ffdggf1d63v1hgsm0s2ddt480000gn/T/ipykernel_14667/788221307.py\", line 6, in <module>\n",
      "    assert lft_str == rgt_str, get_string_diff(lft_str, rgt_str)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: lft_str != rgt_str\n",
      "hello\n",
      " |   \n",
      "hallo\n"
     ]
    }
   ],
   "source": [
    "def get_string_diff(lft_str: str, rgt_str: str) -> str:\n",
    "    return \"lft_str != rgt_str\\n\" + pk.highlight_string_differences(lft_str, rgt_str)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert lft_str == rgt_str, get_string_diff(lft_str, rgt_str)\n",
    "except AssertionError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `timekit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock datetime\n",
    "traveller = time_machine.travel(dt.datetime(2024, 1, 1, 0, 0, 0))\n",
    "traveller.start();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01T01:00:00.003316+01:00'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01T00:00:00.009919+00:00'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.timestamp(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01T01:00:00.015242+01:00'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.timestamp(\"CET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-31T14:00:00.019510-10:00'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.timestamp(\"US/Hawaii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01T09:00:00.026142+09:00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.timestamp(\"Asia/Tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "traveller.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `stopwatch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock datetime\n",
    "traveller = time_machine.travel(dt.datetime(2024, 1, 1, 12, 0, 0))\n",
    "traveller.start();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use as context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01T13:00:00.003586+01:00 -> 2024-01-01T13:00:00.055359+01:00 took 0.051773s\n"
     ]
    }
   ],
   "source": [
    "with tk.stopwatch():\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stopwatch` with different timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01T12:00:00.058243+00:00 -> 2024-01-01T12:00:00.113373+00:00 took 0.05513s - timezone example\n"
     ]
    }
   ],
   "source": [
    "with tk.stopwatch(\"timezone example\", timezone=\"UTC\"):\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 01 Jan 2024 12:00:00 -> Mon, 01 Jan 2024 12:00:00 took 0s - format example\n"
     ]
    }
   ],
   "source": [
    "with tk.stopwatch(\"format example\", timezone=\"UTC\", fmt=\"%a, %d %b %Y %H:%M:%S\"):\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use as decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tk.stopwatch()\n",
    "def func():\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01T13:00:00.181272+01:00 -> 2024-01-01T13:00:00.286460+01:00 took 0.105188s - func\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tk.stopwatch(\"my label\")\n",
    "def func_with_label():\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01T13:00:00.296208+01:00 -> 2024-01-01T13:00:00.398361+01:00 took 0.102153s - my label\n"
     ]
    }
   ],
   "source": [
    "func_with_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "traveller.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sparkkit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from onekit import sparkkit as sk\n",
    "from onekit.exception import OnekitError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/22 07:41:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[1]\")\n",
    "    .appName(\"spark-session-docs\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 1)\n",
    "    .config(\"spark.default.parallelism\", os.cpu_count())\n",
    "    .config(\"spark.rdd.compress\", False)\n",
    "    .config(\"spark.shuffle.compress\", False)\n",
    "    .config(\"spark.dynamicAllocation.enabled\", False)\n",
    "    .config(\"spark.executor.cores\", 1)\n",
    "    .config(\"spark.executor.instances\", 1)\n",
    "    .config(\"spark.ui.enabled\", False)\n",
    "    .config(\"spark.ui.showConsoleProgress\", False)\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `union` + `peek`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: long (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: string (nullable = true)\n",
      "\n",
      "shape=(6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0c77b caption {\n",
       "  font-size: 120%;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_0c77b_row1_col2, #T_0c77b_row2_col1, #T_0c77b_row4_col2 {\n",
       "  color: lightgray;\n",
       "  background-color: transparent;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0c77b\">\n",
       "  <caption>before</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0c77b_level0_col0\" class=\"col_heading level0 col0\" >x</th>\n",
       "      <th id=\"T_0c77b_level0_col1\" class=\"col_heading level0 col1\" >y</th>\n",
       "      <th id=\"T_0c77b_level0_col2\" class=\"col_heading level0 col2\" >z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0c77b_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_0c77b_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_0c77b_row0_col1\" class=\"data row0 col1\" >2.718</td>\n",
       "      <td id=\"T_0c77b_row0_col2\" class=\"data row0 col2\" >a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c77b_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_0c77b_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "      <td id=\"T_0c77b_row1_col1\" class=\"data row1 col1\" >4.14</td>\n",
       "      <td id=\"T_0c77b_row1_col2\" class=\"data row1 col2\" >NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c77b_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_0c77b_row2_col0\" class=\"data row2 col0\" >5</td>\n",
       "      <td id=\"T_0c77b_row2_col1\" class=\"data row2 col1\" >NULL</td>\n",
       "      <td id=\"T_0c77b_row2_col2\" class=\"data row2 col2\" >c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c77b_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_0c77b_row3_col0\" class=\"data row3 col0\" >7</td>\n",
       "      <td id=\"T_0c77b_row3_col1\" class=\"data row3 col1\" >8.28</td>\n",
       "      <td id=\"T_0c77b_row3_col2\" class=\"data row3 col2\" >d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c77b_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_0c77b_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_0c77b_row4_col1\" class=\"data row4 col1\" >1.414</td>\n",
       "      <td id=\"T_0c77b_row4_col2\" class=\"data row4 col2\" >NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c77b_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_0c77b_row5_col0\" class=\"data row5 col0\" >2_000</td>\n",
       "      <td id=\"T_0c77b_row5_col1\" class=\"data row5 col1\" >3_000.1</td>\n",
       "      <td id=\"T_0c77b_row5_col2\" class=\"data row5 col2\" >f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10b94bb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f33dc caption {\n",
       "  font-size: 120%;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_f33dc_row1_col2, #T_f33dc_row2_col2 {\n",
       "  color: lightgray;\n",
       "  background-color: transparent;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f33dc\">\n",
       "  <caption>after</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f33dc_level0_col0\" class=\"col_heading level0 col0\" >x</th>\n",
       "      <th id=\"T_f33dc_level0_col1\" class=\"col_heading level0 col1\" >y</th>\n",
       "      <th id=\"T_f33dc_level0_col2\" class=\"col_heading level0 col2\" >z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f33dc_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_f33dc_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_f33dc_row0_col1\" class=\"data row0 col1\" >2.718</td>\n",
       "      <td id=\"T_f33dc_row0_col2\" class=\"data row0 col2\" >a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33dc_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_f33dc_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "      <td id=\"T_f33dc_row1_col1\" class=\"data row1 col1\" >4.14</td>\n",
       "      <td id=\"T_f33dc_row1_col2\" class=\"data row1 col2\" >NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f33dc_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_f33dc_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_f33dc_row2_col1\" class=\"data row2 col1\" >1.414</td>\n",
       "      <td id=\"T_f33dc_row2_col2\" class=\"data row2 col2\" >NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10ecc58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = (\n",
    "    sk.union(\n",
    "        spark.createDataFrame([dict(x=1, y=2.718, z=\"a\"), dict(x=3, y=4.14, z=None)]),\n",
    "        spark.createDataFrame([dict(x=5, y=None, z=\"c\"), dict(x=7, y=8.28, z=\"d\")]),\n",
    "        spark.createDataFrame(\n",
    "            [dict(x=0, y=1.414, z=None), dict(x=2000, y=3000.1, z=\"f\")]\n",
    "        ),\n",
    "    )\n",
    "    .transform(\n",
    "        lambda df: sk.peek(\n",
    "            df, n=20, shape=True, cache=True, schema=True, label=\"before\"\n",
    "        )\n",
    "    )\n",
    "    .where(F.col(\"x\") + F.col(\"y\") < 10)\n",
    "    .transform(lambda df: sk.peek(df, label=\"after\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "|  x|    y|   z|\n",
      "+---+-----+----+\n",
      "|  1|2.718|   a|\n",
      "|  3| 4.14|NULL|\n",
      "|  0|1.414|NULL|\n",
      "+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `assert_schema_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/zd/ffdggf1d63v1hgsm0s2ddt480000gn/T/ipykernel_14667/3363102269.py\", line 5, in <module>\n",
      "    sk.assert_schema_equal(lft_df, rgt_df)\n",
      "  File \"/Users/eugen/Workspace/onekit/src/onekit/sparkkit.py\", line 389, in assert_schema_equal\n",
      "    raise SchemaMismatchError(lft_schema, rgt_schema)\n",
      "onekit.exception.SchemaMismatchError: num_diff=10\n",
      "struct<x:bigint,y:bigint>\n",
      "               ||||||||||\n",
      "struct<x:bigint>\n"
     ]
    }
   ],
   "source": [
    "lft_df = spark.createDataFrame([dict(x=1, y=2), dict(x=3, y=4)])\n",
    "rgt_df = spark.createDataFrame([dict(x=1), dict(x=3)])\n",
    "\n",
    "try:\n",
    "    sk.assert_schema_equal(lft_df, rgt_df)\n",
    "except OnekitError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `assert_row_count_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/zd/ffdggf1d63v1hgsm0s2ddt480000gn/T/ipykernel_14667/2179063999.py\", line 5, in <module>\n",
      "    sk.assert_row_count_equal(lft_df, rgt_df)\n",
      "  File \"/Users/eugen/Workspace/onekit/src/onekit/sparkkit.py\", line 302, in assert_row_count_equal\n",
      "    raise RowCountMismatchError(num_lft, num_rgt)\n",
      "onekit.exception.RowCountMismatchError: num_lft=2, num_rgt=1, num_diff=1\n"
     ]
    }
   ],
   "source": [
    "lft_df = spark.createDataFrame([dict(x=1, y=2), dict(x=3, y=4)])\n",
    "rgt_df = spark.createDataFrame([dict(x=1)])\n",
    "\n",
    "try:\n",
    "    sk.assert_row_count_equal(lft_df, rgt_df)\n",
    "except OnekitError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `assert_row_value_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/zd/ffdggf1d63v1hgsm0s2ddt480000gn/T/ipykernel_14667/2487993813.py\", line 5, in <module>\n",
      "    sk.assert_row_value_equal(lft_df, rgt_df)\n",
      "  File \"/Users/eugen/Workspace/onekit/src/onekit/sparkkit.py\", line 346, in assert_row_value_equal\n",
      "    raise RowValueMismatchError(lft_rows, rgt_rows, num_lft, num_rgt)\n",
      "onekit.exception.RowValueMismatchError: num_lft=1, num_rgt=2\n"
     ]
    }
   ],
   "source": [
    "lft_df = spark.createDataFrame([dict(x=1, y=2), dict(x=3, y=4)])\n",
    "rgt_df = spark.createDataFrame([dict(x=3, y=4), dict(x=5, y=6), dict(x=7, y=8)])\n",
    "\n",
    "try:\n",
    "    sk.assert_row_value_equal(lft_df, rgt_df)\n",
    "except OnekitError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
