{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pythonkit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import functools\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import time_machine\n",
    "from toolz import curried\n",
    "\n",
    "from onekit import pythonkit as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock datetime\n",
    "traveller = time_machine.travel(dt.datetime(2024, 1, 1, 0, 0, 0))\n",
    "traveller.start();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01 00:00:00'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01 00:00:00'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.timestamp(\"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01 01:00:00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.timestamp(\"CET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-31 14:00:00'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.timestamp(\"US/Hawaii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01 09:00:00'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk.timestamp(\"Asia/Tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traveller.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `stopwatch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite defaults for illustrative purposes\n",
    "stopwatch = functools.partial(\n",
    "    pk.stopwatch,\n",
    "    fmt=\"%a, %d %b %Y %H:%M:%S\",\n",
    "    flush=False,\n",
    ")\n",
    "\n",
    "# mock datetime\n",
    "traveller = time_machine.travel(dt.datetime(2024, 1, 1, 12, 0, 0))\n",
    "traveller.start();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use as context manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: Measure total elapsed time of multiple statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 01 Jan 2024 12:00:00 -> Mon, 01 Jan 2024 12:00:00 = 0.100278s - example 1\n"
     ]
    }
   ],
   "source": [
    "with stopwatch(\"example 1\"):\n",
    "    time.sleep(0.05)\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Measure total elapsed time of multiple `stopwatch` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 01 Jan 2024 12:00:00 -> Mon, 01 Jan 2024 12:00:00 = 0.050169s - example 2 - stopwatch 1\n",
      "Mon, 01 Jan 2024 12:00:00 -> Mon, 01 Jan 2024 12:00:00 = 0.050182s - example 2 - stopwatch 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.100351s - total elapsed time"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with stopwatch(\"example 2 - stopwatch 1\") as sw1:\n",
    "    time.sleep(0.05)\n",
    "\n",
    "with stopwatch(\"example 2 - stopwatch 2\") as sw2:\n",
    "    time.sleep(0.05)\n",
    "\n",
    "sw1 + sw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%a, %d %b %Y %H:%M:%S'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw1.fmt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3: `stopwatch` with different timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 01 Jan 2024 13:00:00 -> Mon, 01 Jan 2024 13:00:00 = 0.050177s - example 3\n"
     ]
    }
   ],
   "source": [
    "with stopwatch(\"example 3\", timezone=\"CET\"):\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use as decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stopwatch(\"example 4\")\n",
    "def func_with_supplied_label():\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 01 Jan 2024 12:00:00 -> Mon, 01 Jan 2024 12:00:00 = 0.10018s - example 4\n"
     ]
    }
   ],
   "source": [
    "func_with_supplied_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stopwatch()\n",
    "def func_with_no_supplied_label():\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon, 01 Jan 2024 12:00:00 -> Mon, 01 Jan 2024 12:00:00 = 0.100216s - func_with_no_supplied_label\n"
     ]
    }
   ],
   "source": [
    "func_with_no_supplied_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traveller.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `flatten`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 2, 3, 4, 'five', 'six', 'seven', 8, 9, 'ten']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irregular_list = [\n",
    "    [\"one\", 2],\n",
    "    3,\n",
    "    [(4, \"five\")],\n",
    "    [[[\"six\"]]],\n",
    "    \"seven\",\n",
    "    [],\n",
    "]\n",
    "\n",
    "list(pk.flatten(irregular_list, 8, [9, (\"ten\",)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `highlight_string_differences`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use in an `assert` statement to get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lft_str = \"hello\"\n",
    "rgt_str = \"hallo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common approach to print values might not be informative enough for subtle differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9990/54865336.py\", line 2, in <module>\n",
      "    assert lft_str == rgt_str, f\"{lft_str} != {rgt_str}\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: hello != hallo\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert lft_str == rgt_str, f\"{lft_str} != {rgt_str}\"\n",
    "except AssertionError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `highlight_string_differences`, it is easier to spot subtle differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9990/788221307.py\", line 6, in <module>\n",
      "    assert lft_str == rgt_str, get_string_diff(lft_str, rgt_str)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: lft_str != rgt_str\n",
      "hello\n",
      " |   \n",
      "hallo\n"
     ]
    }
   ],
   "source": [
    "def get_string_diff(lft_str: str, rgt_str: str) -> str:\n",
    "    return \"lft_str != rgt_str\\n\" + pk.highlight_string_differences(lft_str, rgt_str)\n",
    "\n",
    "\n",
    "try:\n",
    "    assert lft_str == rgt_str, get_string_diff(lft_str, rgt_str)\n",
    "except AssertionError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `date_count_forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01', '2024-05-01']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# month sequence - first date\n",
    "curried.pipe(\n",
    "    pk.date_count_forward(dt.date(2024, 1, 1)),\n",
    "    curried.filter(lambda d: d.day == 1),\n",
    "    curried.map(pk.date_to_str),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01-31', '2024-02-29', '2024-03-31', '2024-04-30', '2024-05-31']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# month sequence - last date\n",
    "curried.pipe(\n",
    "    pk.date_count_forward(dt.date(2024, 1, 1)),\n",
    "    curried.filter(lambda d: d.day == 1),\n",
    "    curried.map(lambda d: pk.last_date_of_month(d.year, d.month)),\n",
    "    curried.map(pk.date_to_str),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01-01', '2024-01-08', '2024-01-15', '2024-01-22', '2024-01-29']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Monday sequence\n",
    "curried.pipe(\n",
    "    pk.date_count_forward(dt.date(2024, 1, 1)),\n",
    "    curried.filter(lambda d: pk.weekday(d) == \"Mon\"),\n",
    "    curried.map(pk.date_to_str),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01-01', '2024-01-15', '2024-01-29', '2024-02-12', '2024-02-26']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick every 14th day\n",
    "curried.pipe(\n",
    "    pk.date_count_forward(dt.date(2024, 1, 1)),\n",
    "    curried.take_nth(14),\n",
    "    curried.map(pk.date_to_str),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: The digits of 22 February 2022 form [a palindrome and an ambigram](https://en.wikipedia.org/wiki/Twosday) in dd-mm-yyyy format.\n",
    "List the next five dates with these properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08-02-2080 ↦ 08022080',\n",
       " '18-02-2081 ↦ 18022081',\n",
       " '28-02-2082 ↦ 28022082',\n",
       " '10-12-2101 ↦ 10122101',\n",
       " '20-12-2102 ↦ 20122102']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_date(d: dt.date, with_hyphen: bool) -> str:\n",
    "    fmt = \"%d-%m-%Y\" if with_hyphen else \"%d%m%Y\"\n",
    "    return d.strftime(fmt)\n",
    "\n",
    "\n",
    "def is_palindrome_date(d: dt.date) -> bool:\n",
    "    d_str = format_date(d, False)\n",
    "    return d_str == d_str[::-1]\n",
    "\n",
    "\n",
    "def is_ambigram_date(d: dt.date) -> bool:\n",
    "    d_str = format_date(d, False)\n",
    "    return set(d_str) <= {\"0\", \"1\", \"2\", \"8\"}\n",
    "\n",
    "\n",
    "def show_date(d: dt.date) -> str:\n",
    "    return f\"{format_date(d, True)} ↦ {format_date(d, False)}\"\n",
    "\n",
    "\n",
    "curried.pipe(\n",
    "    pk.date_count_forward(dt.date(2022, 2, 23)),\n",
    "    curried.filter(is_palindrome_date),\n",
    "    curried.filter(is_ambigram_date),\n",
    "    curried.map(show_date),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `date_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01-01', '2024-02-01', '2024-03-01', '2024-04-01', '2024-05-01']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# month sequence - first date\n",
    "curried.pipe(\n",
    "    pk.date_range(dt.date(2024, 1, 1), dt.date(2024, 5, 31)),\n",
    "    curried.filter(lambda d: d.day == 1),\n",
    "    curried.map(pk.date_to_str),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-01-31', '2024-02-29', '2024-03-31', '2024-04-30', '2024-05-31']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# month sequence - last date\n",
    "curried.pipe(\n",
    "    pk.date_range(dt.date(2024, 1, 1), dt.date(2024, 5, 31)),\n",
    "    curried.filter(lambda d: d.day == 1),\n",
    "    curried.map(lambda d: pk.last_date_of_month(d.year, d.month)),\n",
    "    curried.map(pk.date_to_str),\n",
    "    curried.take(5),\n",
    "    list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sparkkit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from onekit import sparkkit as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/26 17:21:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[1]\")\n",
    "    .appName(\"spark-session-docs\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 1)\n",
    "    .config(\"spark.default.parallelism\", os.cpu_count())\n",
    "    .config(\"spark.rdd.compress\", False)\n",
    "    .config(\"spark.shuffle.compress\", False)\n",
    "    .config(\"spark.dynamicAllocation.enabled\", False)\n",
    "    .config(\"spark.executor.cores\", 1)\n",
    "    .config(\"spark.executor.instances\", 1)\n",
    "    .config(\"spark.ui.enabled\", False)\n",
    "    .config(\"spark.ui.showConsoleProgress\", False)\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `union` + `peek`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- x: long (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: string (nullable = true)\n",
      "\n",
      "shape=(6, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_70027 caption {\n",
       "  font-size: 120%;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_70027_row1_col2, #T_70027_row2_col1, #T_70027_row4_col2 {\n",
       "  color: lightgray;\n",
       "  background-color: transparent;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_70027\">\n",
       "  <caption>before</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_70027_level0_col0\" class=\"col_heading level0 col0\" >x</th>\n",
       "      <th id=\"T_70027_level0_col1\" class=\"col_heading level0 col1\" >y</th>\n",
       "      <th id=\"T_70027_level0_col2\" class=\"col_heading level0 col2\" >z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_70027_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_70027_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_70027_row0_col1\" class=\"data row0 col1\" >2.718</td>\n",
       "      <td id=\"T_70027_row0_col2\" class=\"data row0 col2\" >a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70027_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_70027_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "      <td id=\"T_70027_row1_col1\" class=\"data row1 col1\" >4.14</td>\n",
       "      <td id=\"T_70027_row1_col2\" class=\"data row1 col2\" >NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70027_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_70027_row2_col0\" class=\"data row2 col0\" >5</td>\n",
       "      <td id=\"T_70027_row2_col1\" class=\"data row2 col1\" >NULL</td>\n",
       "      <td id=\"T_70027_row2_col2\" class=\"data row2 col2\" >c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70027_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_70027_row3_col0\" class=\"data row3 col0\" >7</td>\n",
       "      <td id=\"T_70027_row3_col1\" class=\"data row3 col1\" >8.28</td>\n",
       "      <td id=\"T_70027_row3_col2\" class=\"data row3 col2\" >d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70027_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_70027_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_70027_row4_col1\" class=\"data row4 col1\" >1.414</td>\n",
       "      <td id=\"T_70027_row4_col2\" class=\"data row4 col2\" >NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_70027_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_70027_row5_col0\" class=\"data row5 col0\" >2_000</td>\n",
       "      <td id=\"T_70027_row5_col1\" class=\"data row5 col1\" >3_000.1</td>\n",
       "      <td id=\"T_70027_row5_col2\" class=\"data row5 col2\" >f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4c59c91150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_53697 caption {\n",
       "  font-size: 120%;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_53697_row1_col2, #T_53697_row2_col2 {\n",
       "  color: lightgray;\n",
       "  background-color: transparent;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_53697\">\n",
       "  <caption>after</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_53697_level0_col0\" class=\"col_heading level0 col0\" >x</th>\n",
       "      <th id=\"T_53697_level0_col1\" class=\"col_heading level0 col1\" >y</th>\n",
       "      <th id=\"T_53697_level0_col2\" class=\"col_heading level0 col2\" >z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_53697_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_53697_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_53697_row0_col1\" class=\"data row0 col1\" >2.718</td>\n",
       "      <td id=\"T_53697_row0_col2\" class=\"data row0 col2\" >a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53697_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_53697_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "      <td id=\"T_53697_row1_col1\" class=\"data row1 col1\" >4.14</td>\n",
       "      <td id=\"T_53697_row1_col2\" class=\"data row1 col2\" >NULL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_53697_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_53697_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_53697_row2_col1\" class=\"data row2 col1\" >1.414</td>\n",
       "      <td id=\"T_53697_row2_col2\" class=\"data row2 col2\" >NULL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f4c2bc7f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = (\n",
    "    sk.union(\n",
    "        spark.createDataFrame([dict(x=1, y=2.718, z=\"a\"), dict(x=3, y=4.14, z=None)]),\n",
    "        spark.createDataFrame([dict(x=5, y=None, z=\"c\"), dict(x=7, y=8.28, z=\"d\")]),\n",
    "        spark.createDataFrame(\n",
    "            [dict(x=0, y=1.414, z=None), dict(x=2000, y=3000.1, z=\"f\")]\n",
    "        ),\n",
    "    )\n",
    "    .transform(\n",
    "        lambda df: sk.peek(\n",
    "            df, n=20, shape=True, cache=True, schema=True, label=\"before\"\n",
    "        )\n",
    "    )\n",
    "    .where(F.col(\"x\") + F.col(\"y\") < 10)\n",
    "    .transform(lambda df: sk.peek(df, label=\"after\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "|  x|    y|   z|\n",
      "+---+-----+----+\n",
      "|  1|2.718|   a|\n",
      "|  3| 4.14|NULL|\n",
      "|  0|1.414|NULL|\n",
      "+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `assert_schema_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9990/791909425.py\", line 5, in <module>\n",
      "    sk.assert_schema_equal(lft_df, rgt_df)\n",
      "  File \"/workspaces/onekit/src/onekit/sparkkit.py\", line 423, in assert_schema_equal\n",
      "    raise SchemaMismatchError(lft_schema, rgt_schema)\n",
      "onekit.sparkkit.SchemaMismatchError: n_diff=10\n",
      "struct<x:bigint,y:bigint>\n",
      "               ||||||||||\n",
      "struct<x:bigint>\n"
     ]
    }
   ],
   "source": [
    "lft_df = spark.createDataFrame([dict(x=1, y=2), dict(x=3, y=4)])\n",
    "rgt_df = spark.createDataFrame([dict(x=1), dict(x=3)])\n",
    "\n",
    "try:\n",
    "    sk.assert_schema_equal(lft_df, rgt_df)\n",
    "except sk.SparkkitError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `assert_row_count_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9990/3542645773.py\", line 5, in <module>\n",
      "    sk.assert_row_count_equal(lft_df, rgt_df)\n",
      "  File \"/workspaces/onekit/src/onekit/sparkkit.py\", line 338, in assert_row_count_equal\n",
      "    raise RowCountMismatchError(n_lft, n_rgt)\n",
      "onekit.sparkkit.RowCountMismatchError: n_lft=2, n_rgt=1, n_diff=1\n"
     ]
    }
   ],
   "source": [
    "lft_df = spark.createDataFrame([dict(x=1, y=2), dict(x=3, y=4)])\n",
    "rgt_df = spark.createDataFrame([dict(x=1)])\n",
    "\n",
    "try:\n",
    "    sk.assert_row_count_equal(lft_df, rgt_df)\n",
    "except sk.SparkkitError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `assert_row_equal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9990/553075025.py\", line 5, in <module>\n",
      "    sk.assert_row_equal(lft_df, rgt_df)\n",
      "  File \"/workspaces/onekit/src/onekit/sparkkit.py\", line 381, in assert_row_equal\n",
      "    raise RowMismatchError(lft_rows, rgt_rows, n_lft, n_rgt)\n",
      "onekit.sparkkit.RowMismatchError: n_lft=1, n_rgt=2\n"
     ]
    }
   ],
   "source": [
    "lft_df = spark.createDataFrame([dict(x=1, y=2), dict(x=3, y=4)])\n",
    "rgt_df = spark.createDataFrame([dict(x=3, y=4), dict(x=5, y=6), dict(x=7, y=8)])\n",
    "\n",
    "try:\n",
    "    sk.assert_row_equal(lft_df, rgt_df)\n",
    "except sk.SparkkitError:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
